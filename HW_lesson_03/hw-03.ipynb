{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "beta_ = 1 # parameter for f-betta measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_id', 'age', 'job', 'marital', 'education', 'default', 'housing',\n",
       "       'loan', 'contact', 'month', 'day_of_week', 'duration', 'campaign',\n",
       "       'pdays', 'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx',\n",
       "       'cons.conf.idx', 'euribor3m', 'nr.employed', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66810d8e6bf2b41c880a7bc6c8a1e295</td>\n",
       "      <td>57</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>...</td>\n",
       "      <td>371</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.299</td>\n",
       "      <td>5099.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ccac3879652b08cb8b44c1920fd93afa</td>\n",
       "      <td>55</td>\n",
       "      <td>unknown</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>...</td>\n",
       "      <td>285</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.860</td>\n",
       "      <td>5191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fcccab4d7a76f70647f015f2c84c2af8</td>\n",
       "      <td>33</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.313</td>\n",
       "      <td>5099.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ed8399278c30678dab739045fa12b440</td>\n",
       "      <td>36</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>...</td>\n",
       "      <td>355</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.967</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1d4d62ac5cabcb48bac7112813f290cb</td>\n",
       "      <td>27</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>...</td>\n",
       "      <td>189</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                _id  age          job  marital    education  \\\n",
       "0  66810d8e6bf2b41c880a7bc6c8a1e295   57   technician  married  high.school   \n",
       "1  ccac3879652b08cb8b44c1920fd93afa   55      unknown  married      unknown   \n",
       "2  fcccab4d7a76f70647f015f2c84c2af8   33  blue-collar  married     basic.9y   \n",
       "3  ed8399278c30678dab739045fa12b440   36       admin.  married  high.school   \n",
       "4  1d4d62ac5cabcb48bac7112813f290cb   27    housemaid  married  high.school   \n",
       "\n",
       "   default housing loan    contact month     ...      duration  campaign  \\\n",
       "0       no      no  yes   cellular   may     ...           371         1   \n",
       "1  unknown     yes   no  telephone   may     ...           285         2   \n",
       "2       no      no   no   cellular   may     ...            52         1   \n",
       "3       no      no   no  telephone   jun     ...           355         4   \n",
       "4       no     yes   no   cellular   jul     ...           189         2   \n",
       "\n",
       "   pdays  previous     poutcome emp.var.rate  cons.price.idx  cons.conf.idx  \\\n",
       "0    999         1      failure         -1.8          92.893          -46.2   \n",
       "1    999         0  nonexistent          1.1          93.994          -36.4   \n",
       "2    999         1      failure         -1.8          92.893          -46.2   \n",
       "3    999         0  nonexistent          1.4          94.465          -41.8   \n",
       "4    999         0  nonexistent          1.4          93.918          -42.7   \n",
       "\n",
       "   euribor3m  nr.employed  \n",
       "0      1.299       5099.1  \n",
       "1      4.860       5191.0  \n",
       "2      1.313       5099.1  \n",
       "3      4.967       5228.1  \n",
       "4      4.963       5228.1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head() #x for x in train.columns if x not in test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    21925\n",
       "1     2787\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of 0's and 1's in target\n",
    "train.loc[:, 'target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[:, 'sample'] = 'train'\n",
    "test.loc[:, 'sample'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 23 columns):\n",
      "_id               41188 non-null object\n",
      "age               41188 non-null int64\n",
      "campaign          41188 non-null int64\n",
      "cons.conf.idx     41188 non-null float64\n",
      "cons.price.idx    41188 non-null float64\n",
      "contact           41188 non-null object\n",
      "day_of_week       41188 non-null object\n",
      "default           41188 non-null object\n",
      "duration          41188 non-null int64\n",
      "education         41188 non-null object\n",
      "emp.var.rate      41188 non-null float64\n",
      "euribor3m         41188 non-null float64\n",
      "housing           41188 non-null object\n",
      "job               41188 non-null object\n",
      "loan              41188 non-null object\n",
      "marital           41188 non-null object\n",
      "month             41188 non-null object\n",
      "nr.employed       41188 non-null float64\n",
      "pdays             41188 non-null int64\n",
      "poutcome          41188 non-null object\n",
      "previous          41188 non-null int64\n",
      "sample            41188 non-null object\n",
      "target            24712 non-null float64\n",
      "dtypes: float64(6), int64(5), object(12)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df = test.append(train).reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### типы исходных данных и заполняемость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24712 entries, 0 to 24711\n",
      "Data columns (total 23 columns):\n",
      "_id               24712 non-null object\n",
      "age               24712 non-null int64\n",
      "job               24712 non-null object\n",
      "marital           24712 non-null object\n",
      "education         24712 non-null object\n",
      "default           24712 non-null object\n",
      "housing           24712 non-null object\n",
      "loan              24712 non-null object\n",
      "contact           24712 non-null object\n",
      "month             24712 non-null object\n",
      "day_of_week       24712 non-null object\n",
      "duration          24712 non-null int64\n",
      "campaign          24712 non-null int64\n",
      "pdays             24712 non-null int64\n",
      "previous          24712 non-null int64\n",
      "poutcome          24712 non-null object\n",
      "emp.var.rate      24712 non-null float64\n",
      "cons.price.idx    24712 non-null float64\n",
      "cons.conf.idx     24712 non-null float64\n",
      "euribor3m         24712 non-null float64\n",
      "nr.employed       24712 non-null float64\n",
      "target            24712 non-null int64\n",
      "sample            24712 non-null object\n",
      "dtypes: float64(5), int64(6), object(12)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "job\n",
      "{'services', 'unemployed', 'admin.', 'technician', 'entrepreneur', 'blue-collar', 'self-employed', 'housemaid', 'student', 'retired', 'management', 'unknown'}\n",
      "\n",
      "\n",
      "==========\n",
      "marital\n",
      "{'married', 'unknown', 'divorced', 'single'}\n",
      "\n",
      "\n",
      "==========\n",
      "education\n",
      "{'unknown', 'illiterate', 'high.school', 'basic.4y', 'basic.9y', 'professional.course', 'basic.6y', 'university.degree'}\n",
      "\n",
      "\n",
      "==========\n",
      "default\n",
      "{'yes', 'unknown', 'no'}\n",
      "\n",
      "\n",
      "==========\n",
      "housing\n",
      "{'yes', 'unknown', 'no'}\n",
      "\n",
      "\n",
      "==========\n",
      "loan\n",
      "{'yes', 'unknown', 'no'}\n",
      "\n",
      "\n",
      "==========\n",
      "contact\n",
      "{'telephone', 'cellular'}\n",
      "\n",
      "\n",
      "==========\n",
      "month\n",
      "{'oct', 'aug', 'sep', 'jun', 'may', 'mar', 'dec', 'jul', 'nov', 'apr'}\n",
      "\n",
      "\n",
      "==========\n",
      "day_of_week\n",
      "{'fri', 'thu', 'mon', 'tue', 'wed'}\n",
      "\n",
      "\n",
      "==========\n",
      "poutcome\n",
      "{'success', 'nonexistent', 'failure'}\n",
      "\n",
      "\n",
      "==========\n",
      "sample\n",
      "{'train'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in train.columns: # перебираем все столбцы\n",
    "    if (str(train[i].dtype) == 'object') & (i!='_id'): # если тип столбца - object\n",
    "        print('='*10)\n",
    "        print(i) # выводим название столбца\n",
    "        print(set(train[i])) # выводим все его значения (но делаем set - чтоб значения не повторялись)\n",
    "        print('\\n') # выводим пустую строку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### обработка категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter # Не считать же частоты самим.\n",
    "Counter(train['day_of_week'].values)\n",
    "\n",
    "for_map = [{'illiterate':1, 'basic.4y':2, 'basic.6y':3, \\\n",
    "    'basic.9y':4, 'high.school':5, 'professional.course':6, 'university.degree':7, 'unknown':-10}, \\\n",
    "{'mar': 3, 'apr': 4, \\\n",
    "    'may': 5, 'jun': 6, 'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12}, \\\n",
    "{'fri': 5, 'mon': 1, 'thu': 2, 'tue': 4, 'wed': 3}]\n",
    "column_order = ['education', 'month', 'day_of_week']\n",
    "\n",
    "column_OneHot = ['job', 'marital', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
    "\n",
    "column_ids = ['_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from sklearn import preprocessing \n",
    "from sklearn.preprocessing import RobustScaler, PolynomialFeatures\n",
    "from sklearn import preprocessing \n",
    "\n",
    "def preproc_data(df_input, column_order, value_order, column_OneHot, column_ids):\n",
    "    df_output = df_input.copy()    \n",
    "    \n",
    "    df_output = df_output.drop(columns=column_ids, axis=1)\n",
    "    \n",
    "    # Recoding categorical\n",
    "    for i in range(len(column_order)):\n",
    "        df_output[column_order[i]] = df_output[column_order[i]].map(value_order[i])\n",
    "    \n",
    "    # OneHotEncoder other categorical\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    # FIT AND TRANSFORM LabelEncoder    \n",
    "    X_2 = df_output[column_OneHot].apply(le.fit_transform)\n",
    "    \n",
    "    enc = preprocessing.OneHotEncoder()\n",
    "    # FIT OneHotEncoder\n",
    "    enc.fit(X_2)\n",
    "    # Transform\n",
    "    onehotlabels = enc.transform(X_2).toarray()\n",
    "    \n",
    "    # concat Numerical features and OneHot-Categorical    \n",
    "    X_3 = df_output[[x for x in df_output.columns if x not in column_OneHot]]\n",
    "    \n",
    "    X_4 = pd.DataFrame(onehotlabels)\n",
    "       \n",
    "    for c in X_4.columns:\n",
    "        X_3[c] = X_4[c].values \n",
    "    \n",
    "    df_output = X_3\n",
    "    return df_output\n",
    "\n",
    "\n",
    "def scaler_data(df_input):\n",
    "    df_output = df_input.copy() \n",
    "    scaler = RobustScaler()\n",
    "    scaler.fit(df_output)    \n",
    "    df_output = scaler.transform(df_output) # http://localhost:8888/notebooks/Google%20Drive/SkillFactory/HW_lesson_03/hw-03.ipynb#    \n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the last element to the first position\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skulivec\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_preproc = df.pipe(preproc_data, column_order, for_map, column_OneHot, column_ids)\n",
    "\n",
    "df_train_preproc = df_preproc.query('sample == \"train\"').drop(['sample'], axis=1)\n",
    "df_test_preproc = df_preproc.query('sample == \"test\"').drop(['sample'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([        'target',            'age',       'campaign',  'cons.conf.idx',\n",
       "       'cons.price.idx',    'day_of_week',       'duration',      'education',\n",
       "         'emp.var.rate',      'euribor3m',          'month',    'nr.employed',\n",
       "                'pdays',       'previous',                0,                1,\n",
       "                      2,                3,                4,                5,\n",
       "                      6,                7,                8,                9,\n",
       "                     10,               11,               12,               13,\n",
       "                     14,               15,               16,               17,\n",
       "                     18,               19,               20,               21,\n",
       "                     22,               23,               24,               25,\n",
       "                     26,               27,               28,               29],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_preproc.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Рисует зависимость предикторов друг от друга\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "df = df_train_preproc[[        'target',            'age',       'campaign',  'cons.conf.idx',\n",
    "       'cons.price.idx',    'day_of_week',       'duration',      'education',\n",
    "         'emp.var.rate',      'euribor3m',          'month',    'nr.employed',\n",
    "                'pdays',       'previous',                0,                1,\n",
    "                      2,                3,                4,                5,\n",
    "                      6,                7,                8,                9,\n",
    "                     10,               11,               12,               13,\n",
    "                     14,               15,               16,               17,\n",
    "                     18,               19,               20,               21,\n",
    "                     22,               23,               24,               25,\n",
    "                     26,               27,               28,               29]]\n",
    "print('df.columns')\n",
    "print(df.columns)\n",
    "g = sns.PairGrid(df, diag_sharey=False, hue=\"target\")\n",    
    "g = g.map_diag(plt.hist)\n",
    "g = g.map_offdiag(plt.scatter)\n",
    "g = g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### выделение предикторов и целевых переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_train_preproc.iloc[:, 1:].values, df_train_preproc.iloc[:, 0].values\n",
    "X_test, y_test = df_test_preproc.iloc[:, 1:].values, df_test_preproc.iloc[:, 0].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### полиномиальные фичи + приведение шкал"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poly = PolynomialFeatures(2)\n",
    "\n",
    "#X = poly.fit_transform(X)\n",
    "#X_test = poly.fit_transform(X_test)\n",
    "\n",
    "X = scaler_data(X)\n",
    "X_test = scaler_data(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_, y_ = X, y # сохраняем для обучения модели в конце"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### выделяем validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=[42, 123, 0]\n",
    "test_size=0.3\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, X_validate, y, y_validate = train_test_split(X_, y_, test_size=test_size, random_state=random_state[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, fbeta_score, average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "\n",
    "c_range = np.logspace(-3, 3, 10) # from 10^(-3)...10^3 with only 10 values\n",
    "scores=[]\n",
    "for C in c_range:\n",
    "    X, X_validate, y, y_validate = train_test_split(X_, y_, test_size=test_size, random_state=random_state) #random.randint(1, 1000))\n",
    "    model = LogisticRegression(penalty='l2', fit_intercept=True, C=C, random_state=random_state, n_jobs=-1)\n",
    "    model.fit(X, y)   \n",
    "    y_lr_proba = model.predict_proba(X_validate)[:,1]\n",
    "    y_lr = model.predict(X_validate)\n",
    "    scores.append(fbeta_score(y_validate,y_lr,beta=beta_))\n",
    "plt.plot(c_range, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c_range[scores==max(scores)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lr_proba=[]\n",
    "y_lr=[]\n",
    "\n",
    "X_validate_2 = X_validate\n",
    "X_2 = X\n",
    "X__2 = X_\n",
    "X_test_2 = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметра регрессии\n",
    "C=[0.06579332246575682, 0.004641588833612777, 0.1] #c_range[scores==max(scores)][0] # 0.06579332246575682   0.004641588833612777\n",
    "print('X_validate_2.shape')\n",
    "print(X_validate_2.shape)\n",
    "for i in range(len(random_state)):\n",
    "    model = LogisticRegression(penalty='l2', fit_intercept=True, C=C[i], random_state=random_state[i], n_jobs=-1)\n",
    "    model.fit(X, y)\n",
    "    y_lr_proba = model.predict_proba(X_validate)[:,1]\n",
    "    y_lr = model.predict(X_validate)\n",
    "    \n",
    "    \n",
    "    X_validate_2 = np.c_[ X_validate_2, model.predict_proba(X_validate)[:,1] ]  \n",
    "    X_2 = np.c_[ X_2, model.predict_proba(X)[:,1] ]\n",
    "    \n",
    "    model.fit(X_, y_)\n",
    "    X__2 = np.c_[ X__2, model.predict_proba(X_)[:,1] ]        \n",
    "    X_test_2 = np.c_[ X_test_2, model.predict_proba(X_test)[:,1] ]\n",
    "    \n",
    "    print('LogisticRegression on Validate (Prec, Recall, Roc, Acc):')\n",
    "    print('Fbeta', fbeta_score(y_validate,y_lr,beta=beta_))\n",
    "    print('Prec', precision_score(y_validate,y_lr))\n",
    "    print('Recall', recall_score(y_validate, y_lr))\n",
    "    print('Roc', roc_auc_score(y_validate, y_lr_proba)) \n",
    "    print('Acc', accuracy_score(y_validate, y_lr))\n",
    "    print('ARS', average_precision_score(y_validate, y_lr))\n",
    "    print('X_validate_2.shape')\n",
    "    print(X_validate_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####### pow 1 (C=0.06579332246575682)\n",
    "LogisticRegression on Validate (Prec, Recall, Roc, Acc):\n",
    "Fbeta 0.4416243654822335\n",
    "Prec 0.6796875\n",
    "Recall 0.40606767794632437\n",
    "Roc 0.9224928012123824\n",
    "Acc 0.9092257890477475\n",
    "\n",
    "####### pow 2 (C=0.06579332246575682)\n",
    "LogisticRegression on Validate (Prec, Recall, Roc, Acc):\n",
    "Fbeta 0.48281092012133464\n",
    "Prec 0.6541095890410958\n",
    "Recall 0.4531435349940688\n",
    "Roc 0.9290409908882861\n",
    "Acc 0.9105745886161316\n",
    "\n",
    "LogisticRegression on Validate (Prec, Recall, Roc, Acc): C=0.46415888336127775\n",
    "Fbeta 0.44952478808117136\n",
    "Prec 0.6717850287907869\n",
    "Recall 0.4151838671411625\n",
    "Roc 0.9256794069632318\n",
    "Acc 0.9104397086592932\n",
    "\n",
    "LogisticRegression on Validate (Prec, Recall, Roc, Acc): C=0.004641588833612777\n",
    "Fbeta 0.43762833675564683\n",
    "Prec 0.6507633587786259\n",
    "Recall 0.4045077105575326\n",
    "Roc 0.9245446173948473\n",
    "Acc 0.9076072295656865\n",
    "\n",
    "####### pow 3 (C=0.06579332246575682)\n",
    "LogisticRegression on Validate (Prec, Recall, Roc, Acc):\n",
    "Fbeta 0.44038805208067405\n",
    "Prec 0.6330275229357798\n",
    "Recall 0.4092526690391459\n",
    "Roc 0.9243077666290631\n",
    "Acc 0.9058537901267871"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### learn model for all train dataset\n",
    "model.fit(X_, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.DataFrame({'_id':test['_id'], 'target':[int(i) for i in vals]}).to_csv('sample_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as randint\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Подбор оптимальных параметров модели на кросс-валидации \n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': randint(4, 8),\n",
    "    'min_samples_leaf': randint(4, 8),\n",
    "    'class_weight': [None, 'balanced']}\n",
    "\n",
    "\n",
    "##### Будем делать 400 запусков поиска\n",
    "cv = StratifiedKFold(n_splits=5, random_state=random_state, shuffle=True)\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=random_state)\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=400, n_jobs=-1,\n",
    "                                   cv=cv, scoring='f1', random_state=random_state) # , 'precision', 'f1', 'recall', 'roc_auc'\n",
    "random_search.fit(X, y)\n",
    "print(random_search.scoring)\n",
    "print('random_search.best_params_')\n",
    "print(random_search.best_params_)\n",
    "print('random_search.best_score_')\n",
    "print(random_search.best_score_)\n",
    "print(random_search.best_estimator_)\n",
    "print('random_search.best_estimator_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WITHOUT Polinomial\n",
    "f1\n",
    "random_search.best_params_\n",
    "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 7, 'min_samples_leaf': 5}\n",
    "random_search.best_score_\n",
    "0.5623051853546034\n",
    "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=7,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=5, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
    "            splitter='best')\n",
    "            \n",
    "precision\n",
    "random_search.best_params_\n",
    "{'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 5}\n",
    "random_search.best_score_\n",
    "0.6466089479600076\n",
    "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=5, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
    "            splitter='best')\n",
    "            \n",
    "roc_auc\n",
    "random_search.best_params_\n",
    "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 7}\n",
    "random_search.best_score_\n",
    "0.9294953638394235\n",
    "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
    "            max_depth=5, max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=7, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
    "            splitter='best')\n",
    "            \n",
    "accuracy\n",
    "random_search.best_params_\n",
    "{'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 5}\n",
    "random_search.best_score_\n",
    "0.911955139322465\n",
    "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=5, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
    "            splitter='best')\n",
    "            \n",
    "\n",
    "average_precision\n",
    "random_search.best_params_\n",
    "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 6, 'min_samples_leaf': 6}\n",
    "random_search.best_score_\n",
    "0.6015547065646177\n",
    "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
    "            max_depth=6, max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=6, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
    "            splitter='best')\n",
    "            \n",
    "WITH Polinomial\n",
    "f1\n",
    "random_search.best_params_\n",
    "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 4}\n",
    "random_search.best_score_\n",
    "0.5806672468481308\n",
    "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=5,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=4, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
    "            splitter='best')\n",
    "\n",
    "precision\n",
    "random_search.best_params_\n",
    "{'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 4}\n",
    "random_search.best_score_\n",
    "0.6517374731505117\n",
    "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=4, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
    "            splitter='best')\n",
    "            \n",
    "roc_auc\n",
    "random_search.best_params_\n",
    "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 4, 'min_samples_leaf': 4}\n",
    "random_search.best_score_\n",
    "0.926554480351135\n",
    "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
    "            max_depth=4, max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=4, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
    "            splitter='best')\n",
    "            \n",
    "accuracy\n",
    "random_search.best_params_\n",
    "{'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 4}\n",
    "random_search.best_score_\n",
    "0.9123598103827032\n",
    "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=4, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
    "            splitter='best')\n",
    "\n",
    "average_precision\n",
    "random_search.best_params_\n",
    "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 6, 'min_samples_leaf': 7}\n",
    "random_search.best_score_\n",
    "0.5971769349065488\n",
    "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=7, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
    "            splitter='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier on Validate:\n",
      "precision\n",
      "Fbeta 0.5744125326370757\n",
      "Prec 0.6386066763425254\n",
      "Recall 0.5219454329774614\n",
      "Roc 0.9193076339420869\n",
      "Acc 0.9120582681413542\n",
      "ARS 0.38767446079177775\n",
      "DecisionTreeClassifier on Validate:\n",
      "recall\n",
      "Fbeta 0.5009475679090335\n",
      "Prec 0.34136891950064574\n",
      "Recall 0.9406880189798339\n",
      "Roc 0.9229623929003984\n",
      "Acc 0.7868896681953061\n",
      "ARS 0.32786565046826954\n",
      "DecisionTreeClassifier on Validate:\n",
      "f1\n",
      "Fbeta 0.6009445100354192\n",
      "Prec 0.5981198589894242\n",
      "Recall 0.6037959667852907\n",
      "Roc 0.9029034618302896\n",
      "Acc 0.9088211491772322\n",
      "ARS 0.4061922640960313\n",
      "DecisionTreeClassifier on Validate:\n",
      "roc_auc\n",
      "Fbeta 0.5463483146067417\n",
      "Prec 0.38802992518703244\n",
      "Recall 0.9228944246737841\n",
      "Roc 0.9319814064927798\n",
      "Acc 0.8257350957647693\n",
      "ARS 0.3668778517561947\n"
     ]
    }
   ],
   "source": [
    "# max precision\n",
    "model = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=5, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
    "            splitter='best')\n",
    "model.fit(X, y)\n",
    "y_lr_proba = model.predict_proba(X_validate)[:,1]\n",
    "y_lr = model.predict(X_validate)\n",
    "print('DecisionTreeClassifier on Validate:')\n",
    "print('precision')\n",
    "print('Fbeta', fbeta_score(y_validate,y_lr,beta=beta_))\n",
    "print('Prec', precision_score(y_validate,y_lr))\n",
    "print('Recall', recall_score(y_validate, y_lr))\n",
    "print('Roc', roc_auc_score(y_validate, y_lr_proba)) \n",
    "print('Acc', accuracy_score(y_validate, y_lr))\n",
    "print('ARS', average_precision_score(y_validate, y_lr))\n",
    "\n",
    "# max recall\n",
    "model = DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=6, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
    "            splitter='best')\n",
    "model.fit(X, y)\n",
    "y_lr_proba = model.predict_proba(X_validate)[:,1]\n",
    "y_lr = model.predict(X_validate)\n",
    "print('DecisionTreeClassifier on Validate:')\n",
    "print('recall')\n",
    "print('Fbeta', fbeta_score(y_validate,y_lr,beta=beta_))\n",
    "print('Prec', precision_score(y_validate,y_lr))\n",
    "print('Recall', recall_score(y_validate, y_lr))\n",
    "print('Roc', roc_auc_score(y_validate, y_lr_proba)) \n",
    "print('Acc', accuracy_score(y_validate, y_lr))\n",
    "print('ARS', average_precision_score(y_validate, y_lr))\n",
    "\n",
    "# max f1\n",
    "model = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=9, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
    "            splitter='best')\n",
    "model.fit(X, y)\n",
    "y_lr_proba = model.predict_proba(X_validate)[:,1]\n",
    "y_lr = model.predict(X_validate)\n",
    "print('DecisionTreeClassifier on Validate:')\n",
    "print('f1')\n",
    "print('Fbeta', fbeta_score(y_validate,y_lr,beta=beta_))\n",
    "print('Prec', precision_score(y_validate,y_lr))\n",
    "print('Recall', recall_score(y_validate, y_lr))\n",
    "print('Roc', roc_auc_score(y_validate, y_lr_proba)) \n",
    "print('Acc', accuracy_score(y_validate, y_lr))\n",
    "print('ARS', average_precision_score(y_validate, y_lr))\n",
    "\n",
    "# max roc_auc\n",
    "model = DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
    "            max_depth=6, max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=9, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
    "            splitter='best')\n",
    "model.fit(X, y)\n",
    "y_lr_proba = model.predict_proba(X_validate)[:,1]\n",
    "y_lr = model.predict(X_validate)\n",
    "print('DecisionTreeClassifier on Validate:')\n",
    "print('roc_auc')\n",
    "print('Fbeta', fbeta_score(y_validate,y_lr,beta=beta_))\n",
    "print('Prec', precision_score(y_validate,y_lr))\n",
    "print('Recall', recall_score(y_validate, y_lr))\n",
    "print('Roc', roc_auc_score(y_validate, y_lr_proba)) \n",
    "print('Acc', accuracy_score(y_validate, y_lr))\n",
    "print('ARS', average_precision_score(y_validate, y_lr))\n",
    "\n",
    "# обучение модели на всём train dataset'е и сохранение результатов, т.к. это лучшая модель\n",
    "model.fit(X_, y_)\n",
    "vals=model.predict(X_test)\n",
    "pd.DataFrame({'_id':test['_id'], 'target':[int(i) for i in vals]}).to_csv('sample_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Попытка сделать стекинг моделей\n",
    "\n",
    "for i in range(len(random_state)):\n",
    "    print('random_state[i]')\n",
    "    print(random_state[i])\n",
    "    model = DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=7,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=5, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=random_state[i],\n",
    "            splitter='best')\n",
    "    model.fit(X, y)\n",
    "    y_lr_proba = model.predict_proba(X_validate)[:,1]\n",
    "    y_lr = model.predict(X_validate)\n",
    "    \n",
    "    X_validate_2 = np.c_[ X_validate_2, model.predict_proba(X_validate)[:,1] ]  \n",
    "    X_2 = np.c_[ X_2, model.predict_proba(X)[:,1] ]\n",
    "    \n",
    "    model.fit(X_, y_)\n",
    "    X__2 = np.c_[ X__2, model.predict_proba(X_)[:,1] ]        \n",
    "    X_test_2 = np.c_[ X_test_2, model.predict_proba(X_test)[:,1] ]\n",
    "       \n",
    "    print('DecisionTreeClassifier on Validate:')\n",
    "    print('Fbeta', fbeta_score(y_validate,y_lr,beta=beta_))\n",
    "    print('Prec', precision_score(y_validate,y_lr))\n",
    "    print('Recall', recall_score(y_validate, y_lr))\n",
    "    print('Roc', roc_auc_score(y_validate, y_lr_proba)) \n",
    "    print('Acc', accuracy_score(y_validate, y_lr))\n",
    "    print('ARS', average_precision_score(y_validate, y_lr))\n",
    "    print('X_validate_2.shape')\n",
    "    print(X_validate_2.shape)       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=7,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=5, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=random_state[0],\n",
    "            splitter='best')\n",
    "\n",
    "model.fit(X_2, y)\n",
    "y_lr_proba = model.predict_proba(X_validate_2)[:,1]\n",
    "y_lr = model.predict(X_validate_2)\n",
    "\n",
    "print('DecisionTreeClassifier-2 on Validate:')\n",
    "print('Fbeta', fbeta_score(y_validate,y_lr,beta=beta_))\n",
    "print('Prec', precision_score(y_validate,y_lr))\n",
    "print('Recall', recall_score(y_validate, y_lr))\n",
    "print('Roc', roc_auc_score(y_validate, y_lr_proba)) \n",
    "print('Acc', accuracy_score(y_validate, y_lr))\n",
    "print('ARS', average_precision_score(y_validate, y_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======= globe 2 ===\n",
    "DecisionTreeClassifier-2 on Validate:\n",
    "Fbeta 0.5751685838952797\n",
    "Prec 0.43206197854588796\n",
    "Recall 0.8600237247924081\n",
    "Roc 0.8814618783096148\n",
    "Acc 0.8555435662260588\n",
    "ARS 0.38749938703714487\n",
    "\n",
    "===============\n",
    "\n",
    "without polinomial f1\n",
    "DecisionTreeClassifier on Validate:\n",
    "Fbeta 0.7230856709628507\n",
    "Prec 0.4007352941176471\n",
    "Recall 0.9051008303677343\n",
    "Roc 0.9134765377833838\n",
    "Acc 0.8353115727002968\n",
    "\n",
    "with polinomial f1\n",
    "DecisionTreeClassifier on Validate:\n",
    "Fbeta 0.7291265871489034\n",
    "Prec 0.41511500547645125\n",
    "Recall 0.8991696322657177\n",
    "Roc 0.925844769235685\n",
    "Acc 0.8444834097653089\n",
    "\n",
    "with polinomial precision\n",
    "DecisionTreeClassifier on Validate:\n",
    "Fbeta 0.518927049385811\n",
    "Prec 0.6709886547811994\n",
    "Recall 0.49110320284697506\n",
    "Roc 0.9092042879375984\n",
    "Acc 0.9147558672781225\n",
    "\n",
    "with polinomial average_precision\n",
    "DecisionTreeClassifier on Validate:\n",
    "Fbeta 0.6154747948417351\n",
    "Prec 0.5879059350503919\n",
    "Recall 0.6227758007117438\n",
    "Roc 0.9173144408742321\n",
    "Acc 0.9074723496088482\n",
    "ARS 0.4090254157188098"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.fit(X__2, y_)\n",
    "vals=model.predict(X_test_2)\n",
    "pd.DataFrame({'_id':test['_id'], 'target':[int(i) for i in vals]}).to_csv('sample_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Подбор оптимальных параметров модели на кросс-валидации \n",
    "param_grid = {\n",
    "    'n_neighbors': randint(3, 8),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'leaf_size': randint(20, 40),\n",
    "    'p': randint(1,2)}\n",
    "##### Будем делать 400 запусков поиска\n",
    "cv = StratifiedKFold(n_splits=5, random_state=random_state, shuffle=True)\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=400, n_jobs=-1,\n",
    "                                   cv=cv, scoring='f1', random_state=random_state) # 'f1', 'precision', 'recall',\n",
    "                                                                                   # 'roc_auc', 'average_precision',\n",
    "                                                                                   # 'accuracy', ''\n",
    "random_search.fit(X, y)\n",
    "print(random_search.scoring)\n",
    "print('random_search.best_params_')\n",
    "print(random_search.best_params_)\n",
    "print('random_search.best_score_')\n",
    "print(random_search.best_score_)\n",
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='minkowski', p=2, n_jobs=-1)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lr = model.predict(X_validate)\n",
    "y_lr_proba = model.predict_proba(X_validate)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier on Validate:\n",
      "Fbeta 0.4549828178694158\n",
      "Prec 0.5408496732026143\n",
      "Recall 0.3926453143534994\n",
      "Roc 0.8441883014135405\n",
      "Acc 0.8930401942271379\n",
      "ARS 0.2814206278538958\n"
     ]
    }
   ],
   "source": [
    "print('KNeighborsClassifier on Validate:')\n",
    "print('Fbeta', fbeta_score(y_validate,y_lr,beta=beta_))\n",
    "print('Prec', precision_score(y_validate,y_lr))\n",
    "print('Recall', recall_score(y_validate, y_lr))\n",
    "print('Roc', roc_auc_score(y_validate, y_lr_proba)) \n",
    "print('Acc', accuracy_score(y_validate, y_lr))\n",
    "print('ARS', average_precision_score(y_validate, y_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучение модели на всём train dataset'е\n",
    "model.fit(X_, y_)\n",
    "vals=model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
